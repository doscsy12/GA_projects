{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "41fcbdd6",
   "metadata": {},
   "source": [
    "# Project 4: West Nile Virus Prediction\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "feffb5e9",
   "metadata": {},
   "source": [
    "## Contents:\n",
    "- [Data](#Data)\n",
    "- [Model](#Model)\n",
    "- [Feature reduction](#Feature-reduction)\n",
    "- [Feature extraction](#Feature-extraction)\n",
    "- [Predicted locations](#Predicted-locations)\n",
    "- [Conclusions](#Conclusions)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bf00d1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries here\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "import seaborn as sns\n",
    "pd.options.mode.chained_assignment = None  # default='warn'\n",
    "\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler, PolynomialFeatures\n",
    "from sklearn.linear_model import (RidgeCV, \n",
    "                                  LassoCV, \n",
    "                                  ElasticNetCV, \n",
    "                                  LogisticRegressionCV,\n",
    "                                  LinearRegression,\n",
    "                                  LogisticRegression)\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.pipeline import Pipeline\n",
    "from sklearn.metrics import (confusion_matrix, \n",
    "                             plot_confusion_matrix, \n",
    "                             roc_auc_score, \n",
    "                             plot_roc_curve, \n",
    "                             accuracy_score,\n",
    "                            )\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, ExtraTreesClassifier, BaggingClassifier, AdaBoostClassifier\n",
    "from sklearn.svm import LinearSVC, SVC\n",
    "\n",
    "import xgboost as xgb\n",
    "import time\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23575ae6",
   "metadata": {},
   "source": [
    "# Data\n",
    "\n",
    "**Data** \n",
    "* train_set.csv: this is the training dataset\n",
    "* test_set.csv: this is the test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0bca40b",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('../data/train_set.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6fead57",
   "metadata": {},
   "outputs": [],
   "source": [
    "test = pd.read_csv('../data/test_set.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "867e5278",
   "metadata": {},
   "outputs": [],
   "source": [
    "# preview train set\n",
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a0296b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0830d890",
   "metadata": {},
   "outputs": [],
   "source": [
    "train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8ceb098",
   "metadata": {},
   "outputs": [],
   "source": [
    "# change date to numerical\n",
    "train['date'] = pd.to_datetime(train['date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0e8bce0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# preview test set\n",
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad73ee0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "914edf05",
   "metadata": {},
   "outputs": [],
   "source": [
    "test.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ff6ce7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# change date to numerical\n",
    "test['date'] = pd.to_datetime(test['date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12bed380",
   "metadata": {},
   "outputs": [],
   "source": [
    "# baseline score\n",
    "train['wnvpresent'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d52c545f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert to binary\n",
    "# 0 means no wnv detected\n",
    "# 1 means wnv detected\n",
    "def rebin_wnvpresent(row): \n",
    "    if row['wnvpresent'] > 0:\n",
    "        row['wnvpresent'] = 1\n",
    "    else:\n",
    "        row['wnvpresent'] = 0\n",
    "    return row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "404f48bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = train.apply(rebin_wnvpresent,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20e42c44",
   "metadata": {},
   "outputs": [],
   "source": [
    "train['wnvpresent'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6ef2316",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47ffe3a2",
   "metadata": {},
   "source": [
    "## Baseline model (with SMOTE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c124515",
   "metadata": {},
   "source": [
    "Let's just start with modeling using one feature. Since 'trap_rank', 'species_nr' has the largest correlation to 'wnvpresent', one of the features will be used. Simplest classification method would be the logistic regression model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "839ae1a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_sm = train[['species_nr']]\n",
    "y_sm = train[['wnvpresent']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec8dba6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "y=train[['wnvpresent']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "468bf81e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# split data\n",
    "Xsm_train, Xsm_valid, ysm_train, ysm_valid = train_test_split(X_sm, y_sm, test_size = 0.33, random_state = 42, stratify =y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be4ecb82",
   "metadata": {},
   "outputs": [],
   "source": [
    "# scaling\n",
    "ss = StandardScaler()\n",
    "\n",
    "Xsm_train_sc = ss.fit_transform(Xsm_train)\n",
    "Xsm_valid_sc = ss.transform(Xsm_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7c24299",
   "metadata": {},
   "outputs": [],
   "source": [
    "# instantiate\n",
    "lr = LogisticRegression()\n",
    "\n",
    "# fit model\n",
    "lr.fit(Xsm_train_sc, ysm_train)\n",
    "\n",
    "# score\n",
    "lr.score(Xsm_train_sc, ysm_train), lr.score(Xsm_valid_sc, ysm_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f15a023",
   "metadata": {},
   "outputs": [],
   "source": [
    "ysm_train.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6ee2c48",
   "metadata": {},
   "source": [
    "Using only one feature, regardless which one feature, would result in high R2 score. This is because the predictive feature is imbalanced in the training set."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1c7d7f8",
   "metadata": {},
   "source": [
    "**with SMOTE**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b42484c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create synthetic data for training set\n",
    "\n",
    "smote = SMOTE()\n",
    "\n",
    "# Xsmote_train, ysmote_train = smote.fit_sample(Xsm_train_sc, ysm_train)\n",
    "Xsmote_train, ysmote_train = smote.fit_resample(Xsm_train_sc, ysm_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc4d890b",
   "metadata": {},
   "outputs": [],
   "source": [
    "smote.fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63fe5f3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "ysmote_train.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cf10f0c",
   "metadata": {},
   "source": [
    "Now, the predictive feature is more balanced."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad60a8df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# instantiate\n",
    "lr2 = LogisticRegression()\n",
    "\n",
    "# fit model\n",
    "lr2.fit(Xsmote_train, ysmote_train)\n",
    "\n",
    "# score\n",
    "lr2.score(Xsmote_train, ysmote_train), lr2.score(Xsm_valid_sc, ysm_valid)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf027708",
   "metadata": {},
   "source": [
    "However, the above scores where training score < test scores suggest significant underfitting. Ways to counteract this is to increase features (have more feature selection) or use a more complex model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f28433a7",
   "metadata": {},
   "source": [
    "### Logistic regression model (with SMOTE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a31a821e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# columns of train with polynomial features\n",
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90f486c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = train.drop(columns=['date','wnvpresent','nummosquitos'])\n",
    "y = train[['wnvpresent']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c65cc94",
   "metadata": {},
   "outputs": [],
   "source": [
    "# split data\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(X, y, test_size = 0.33, random_state = 42, stratify =y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38abb850",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe = Pipeline([\n",
    "        ('scale', StandardScaler()),\n",
    "        ('sampling', SMOTE()),\n",
    "        ('logreg', LogisticRegression(max_iter=1_000, solver='saga'))\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b37a84c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# regardless of parameters, there is overfitting.\n",
    "pipe_params = {\n",
    "    'sampling__sampling_strategy': ['minority', 'not minority', 'auto'],\n",
    "    'sampling__k_neighbors': [250],   # tried 1-10000\n",
    "    'logreg__penalty': ['l2', 'l1'],   # tried 'l2', 'l1', 'elastinet'\n",
    "    'logreg__C': [1] # tried 1-20\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1c9e9c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "grid = GridSearchCV(pipe, pipe_params, scoring='roc_auc', n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "346a8b15",
   "metadata": {},
   "outputs": [],
   "source": [
    "grid.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1c0af04",
   "metadata": {},
   "outputs": [],
   "source": [
    "grid.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5571f30",
   "metadata": {},
   "outputs": [],
   "source": [
    "grid.score(X_train, y_train), grid.score(X_valid, y_valid)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12c03723",
   "metadata": {},
   "source": [
    "Regardless of pipe_params used, there is overfitting. There is a lot of multicollinearity, and features have to be dropped before modeling.\n",
    "<br>\n",
    "<br> Since there might be too many variables with high multicollinearity, we need to reduce number of features and/or utilise PCA to transform the data first. We approached this based on **feature reduction** and **feature extraction**. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21bc9569",
   "metadata": {},
   "source": [
    "## Feature reduction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f7558d2",
   "metadata": {},
   "source": [
    "We conduct several models based on a reduced number of features.\n",
    "\n",
    "**Drop Column: ```Week``` & ```Date```**\n",
    "\n",
    "While our graphs had provided meaningful visualization as to the prevalence of mosquitos and presence of WNV in weekly periods, we have dropped this variable in testing our logistic models. Mosquitos do not adhere to our human-based calendar groupings such as 'week' and 'date'; their activities are influenced by weather patterns. Due to climate change, weather patterns have shifted such that static human-based calendar groupings are not a precise indicator of seasons. For instance, while 'Summer' starts on June 21, the weather in June 21, 1990 is different than that of June 21, 2021. As static human-based groupings do not affect mosquito life cycle and activity, we believe that excluding such features would provide us with more accurate results.\n",
    "\n",
    "We had also taken an into account our preliminary models in dropping these columns. In running our preliminary models including human-based calendar groupings, we found that as the most important feature, 'week' held a significant weight (143x) when compared to the second and third-most important feature, wetbulb and stnpressure (35x and 17x respectively). This means that as week increases by one, the probability of a trap capturing a WNV-infected mosquito is 143 times more likely, whereas an increase in one degree (Fahrenheit) in wetbulb or an increase of one inch in mercury-based measurement (Hg) results in a 35x and 17x likelihood of a WNV mosquito being present. Due to this massive difference in magnitude between the most important feature as compared to the rest, we believe that it is unwise to include the 'week' feature in our model.\n",
    "\n",
    "\n",
    "**Drop Columns: ```Wnvpresent``` & ```Nummosquitos```**\n",
    "\n",
    "We dropped the columns ```wnvpresent``` and ```nummosquitos``` as they are our target variables and should not be included in our training set.\n",
    "\n",
    "**Drop Columns: ```Tmin``` & ```Tmax```**\n",
    "\n",
    "We dropped the columns ```Tmin``` and ```Tmax``` due to multicollinearity with ```Tavg```. We believe that ```Tavg``` provides us a better gauge of the day's temperature rather than using the minimum and maximum temperature of the day.\n",
    "\n",
    "**Drop Column: ```trap_rank```**\n",
    "\n",
    "We dropped ```trap_rank``` as this is our engineered feature based on our target variables. Including this feature in our model would result in leakage to our data and this will result in an overfitting of our training models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a675460",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = train.drop(columns=['week', 'date', 'wnvpresent', 'nummosquitos',\n",
    "                        'tmin', 'tmax', 'trap_rank'])\n",
    "\n",
    "y = train['wnvpresent'].map(lambda x:0 if x == 0 else 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7787bba5",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y,\n",
    "                                                    random_state=42,\n",
    "                                                    stratify=y\n",
    "                                                   )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae6e2f2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "kaggle_X = test[['species_nr', 'latitude', 'longitude', 'addressaccuracy', 'tavg', \n",
    "                 'depart', 'dewpoint', 'wetbulb', 'sunrise', 'sunset', 'preciptotal', \n",
    "                 'stnpressure', 'sealevel', 'resultspeed', 'resultdir', 'avgspeed', \n",
    "                 'temp_diff', 'year', 'FG', 'TS', 'lag_1_tavg', 'lag_2_tavg', \n",
    "                 'lag_1_preciptotal', 'lag_2_preciptotal']]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "898cf03f",
   "metadata": {},
   "source": [
    "### Loop models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49d6e3f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = pd.DataFrame()\n",
    "result_columns = ['Model', 'Accuracy', 'Specificity', 'Sensitivity', 'ROC_AUC']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9eb08256",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gs_model(gs_name, model_name):\n",
    "    global result\n",
    "    duration = time.time()\n",
    "    gs_name.fit(X_train, y_train)\n",
    "    tn, fp, fn, tp = confusion_matrix(y_test, gs_name.predict(X_test)).ravel()\n",
    "    accuracy = round((tp+tn)/(tn+fp+fn+tp),3)*100 \n",
    "    sensitivity = round((tp)/(tp+fn),3)*100\n",
    "    specificity = round(tn/(tn+fp),3)*100\n",
    "    roc_auc = round(roc_auc_score(y_test, gs_name.best_estimator_.predict(X_test)),3)\n",
    "    \n",
    "    result_new = pd.DataFrame([model_name, \n",
    "                               accuracy,\n",
    "                               specificity,\n",
    "                               sensitivity,\n",
    "                               roc_auc\n",
    "                               ], index=result_columns).T\n",
    "    \n",
    "    result = pd.concat(objs=(result, result_new), axis=0)\n",
    "    \n",
    "    plot_confusion_matrix(gs_name, \n",
    "                          X_test, y_test, \n",
    "                          cmap='Blues', \n",
    "                          values_format='d',\n",
    "                          display_labels=['No WNV', 'WNV']\n",
    "                         );\n",
    "    plt.title(model_name)\n",
    "    print(f'Model Best Params: {gs_name.best_params_}')\n",
    "    print(f'Process took {round((time.time()-duration)/60,1)} minutes')\n",
    "    return result.set_index('Model')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48bae311",
   "metadata": {},
   "source": [
    "### Logistic Classifier Models\n",
    "\n",
    "We conduct several classifier models based on different penalization methods and classifier models."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7649fec9",
   "metadata": {},
   "source": [
    "#### SS, Smote, Logistic (Ridge)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ed07422",
   "metadata": {},
   "outputs": [],
   "source": [
    "smote = SMOTE()\n",
    "ss = StandardScaler()\n",
    "logit = LogisticRegressionCV()\n",
    "\n",
    "pipe_ss_smote_logit_ridge = Pipeline([\n",
    "    ('ss', ss),\n",
    "    ('smote', smote),\n",
    "    ('logit', logit),\n",
    "])\n",
    "\n",
    "pipe_ss_smote_logit_ridge_params = {\n",
    "    'smote__k_neighbors': [5], # 3, 10, 15\n",
    "    'smote__random_state': [42],\n",
    "    'smote__n_jobs': [-1],\n",
    "    'smote__sampling_strategy': ['minority'],\n",
    "    'logit__cv': [15], #5, 10, 20, 25\n",
    "    'logit__n_jobs': [-1],\n",
    "    'logit__random_state': [42],\n",
    "    'logit__scoring': ['roc_auc'],\n",
    "    'logit__solver': ['saga'],\n",
    "    'logit__max_iter': [10_000],\n",
    "}\n",
    "\n",
    "gs_ss_smote_logit_ridge = GridSearchCV(\n",
    "    estimator=pipe_ss_smote_logit_ridge,\n",
    "    param_grid=pipe_ss_smote_logit_ridge_params,\n",
    "    scoring='roc_auc',\n",
    "    cv=5\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acde6349",
   "metadata": {},
   "outputs": [],
   "source": [
    "gs_model(gs_ss_smote_logit_ridge, 'SS, Smote, Logit-Ridge')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80e67730",
   "metadata": {},
   "source": [
    "**Observations and Interpretation of Feature Importance**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d3bea3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "feat_impt = pd.DataFrame(\n",
    "    gs_ss_smote_logit_ridge.best_estimator_['logit'].coef_[0], \n",
    "    index=X_train.columns)\n",
    "\n",
    "logit_ridge_head = pd.DataFrame(np.exp(feat_impt[0].sort_values(ascending=False).head(5))).T\n",
    "logit_ridge_tail = pd.DataFrame(np.exp(feat_impt[0].sort_values(ascending=False).tail(5))).T\n",
    "\n",
    "display(logit_ridge_head, logit_ridge_tail)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4898cf2",
   "metadata": {},
   "source": [
    "We find that the features we used to create out models have differing magnitudes of impact.\n",
    "As the sun rises later, there is a much higher likelihood of observing a WNV-infected mosquito.\n",
    "In any given day, an increase in one minute in the sunrise time results in a 13.6x likelihood of a WNV-infected mosquito to be found.\n",
    "An increase of 1 Fahrenheit in average temperature results in a 5.3x likelihood of a WNV-infected mosquito to be found.\n",
    "Precipitation negatively affects the likelihood of observing a WNV-infected mosquito.\n",
    "An increase in precipitation by 1 inch results in a 0.67x likelihood of a WNV-infected mosquito to be found.\n",
    "The positive relationship in average temperature and inverse relationship in precipitation is similar to that we have identified in our previous EDA."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cdcfcfb",
   "metadata": {},
   "source": [
    "#### SS, Smote, Logistic (Lasso)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52346592",
   "metadata": {},
   "outputs": [],
   "source": [
    "smote = SMOTE()\n",
    "ss = StandardScaler()\n",
    "logit = LogisticRegressionCV()\n",
    "\n",
    "pipe_ss_smote_logit_lasso = Pipeline([\n",
    "    ('ss', ss),\n",
    "    ('smote', smote),\n",
    "    ('logit', logit),\n",
    "])\n",
    "\n",
    "pipe_ss_smote_logit_lasso_params = {\n",
    "    'smote__k_neighbors': [3], # 5, 10, 15\n",
    "    'smote__random_state': [42],\n",
    "    'smote__n_jobs': [-1],\n",
    "    'smote__sampling_strategy': ['minority'],\n",
    "    'logit__cv': [20], # 5, 10, 15, 25\n",
    "    'logit__n_jobs': [-1],\n",
    "    'logit__random_state': [42],\n",
    "    'logit__scoring': ['roc_auc'],\n",
    "    'logit__solver': ['saga'],\n",
    "    'logit__max_iter': [10_000],\n",
    "    'logit__penalty': ['l1'],\n",
    "}\n",
    "\n",
    "gs_ss_smote_logit_lasso = GridSearchCV(\n",
    "    estimator=pipe_ss_smote_logit_lasso,\n",
    "    param_grid=pipe_ss_smote_logit_lasso_params,\n",
    "    scoring='roc_auc',\n",
    "    cv=5\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "110debb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "gs_model(gs_ss_smote_logit_lasso, 'SS, Smote, Logit-Lasso')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ced6148d",
   "metadata": {},
   "source": [
    "**Observations and Interpretation of Feature Importance**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80537e56",
   "metadata": {},
   "outputs": [],
   "source": [
    "feat_impt = pd.DataFrame(\n",
    "    gs_ss_smote_logit_lasso.best_estimator_['logit'].coef_[0], \n",
    "    index=X_train.columns)\n",
    "\n",
    "logit_lasso_head = pd.DataFrame(np.exp(feat_impt[0].sort_values(ascending=False).head(5))).T\n",
    "logit_lasso_tail = pd.DataFrame(np.exp(feat_impt[0].sort_values(ascending=False).tail(5))).T\n",
    "\n",
    "display(logit_lasso_head, logit_lasso_tail)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45c93aa1",
   "metadata": {},
   "source": [
    "We find that the features we used to create out models have differing magnitudes of impact.\n",
    "As the sun rises later, there is a much higher likelihood of observing a WNV-infected mosquito.\n",
    "In any given day, an increase in one minute in the sunrise time results in a 13x likelihood of a WNV-infected mosquito to be found.\n",
    "An increase of 1 Fahrenheit in average temperature results in a 5.5x likelihood of a WNV-infected mosquito to be found.\n",
    "Precipitation negatively affects the likelihood of observing a WNV-infected mosquito.\n",
    "An increase in precipitation by 1 inch results in a 0.67x likelihood of a WNV-infected mosquito to be found.\n",
    "The positive relationship in average temperature and inverse relationship in precipitation is similar to that we have identified in our previous EDA."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a07906d6",
   "metadata": {},
   "source": [
    "#### Logistic Classifier Model Combined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37c17310",
   "metadata": {},
   "outputs": [],
   "source": [
    "logit_combined_head = pd.concat(objs=(logit_ridge_head, logit_lasso_head), axis=0).reset_index(drop=True)\n",
    "logit_combined_head.index = ['Ridge Head', 'Lasso Head']\n",
    "\n",
    "logit_combined_tail = pd.concat(objs=(logit_ridge_tail, logit_lasso_tail), axis=0).reset_index(drop=True)\n",
    "logit_combined_tail.index = ['Ridge Tail', 'Lasso Tail']\n",
    "\n",
    "display(logit_combined_head)\n",
    "display(logit_combined_tail)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04b37d75",
   "metadata": {},
   "source": [
    "**Feature Importance Comparison**\n",
    "\n",
    "We compare the feature importances of the top 5 heads and tails between our model.\n",
    "\n",
    "We find that 4 out of the top 5 head features used in the logistic classification model are identical.\n",
    "However, there is a difference in magnitude of effect. The magnitudes in the lasso features are more evenly distributed than the ridge feature importances.\n",
    "The difference in magnitude is caused by the different types of penalization between the two regularization models.\n",
    "We find that all of the top tail features used in the logistic classification model are identical.\n",
    "However, similar to #2, there is a difference in the magnitude of effect. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77b761a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "display(result.set_index('Model'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c41bcc74",
   "metadata": {},
   "source": [
    "**Model Comparison**\n",
    "\n",
    "We observe the metrics in our observations and find that our L1 penalized model consistently performs better in our metrics of concern: Specificity and ROC_AUC. As we expand our model to include other potential metrics that may be of relevance, we find that our lasso model still performs better for accuracy and specificity. Running our models on Kaggle for testing, we obtain the following result:\n",
    "\n",
    "|Model|Sensitivity|ROC_AUC|Kaggle Score|\n",
    "|-----|-----------|-------|------------|\n",
    "|SS, Smote, Logit-Ridge|0.737|0.731|0.71532|\n",
    "|SS, Smote, Logit-Lasso|0.746|0.738|0.72469|\n",
    "\n",
    "Knowing this, we believe that our lasso model is the preferred logistic classification model. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4896c90b",
   "metadata": {},
   "source": [
    "### Tree-Based Models\n",
    "\n",
    "In this section, we conduct several tree-based models. Below is the list of tree-based models we run:\n",
    "\n",
    "    1. Decision Tree Classifier\n",
    "    2. Boostrap Aggregating (Bagging) Classifier\n",
    "    3. XGBoost Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0a70ba6",
   "metadata": {},
   "source": [
    "#### Decision Tree Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5319a2ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "dt = DecisionTreeClassifier()\n",
    "\n",
    "pipe_ss_smote_dt = Pipeline([\n",
    "    ('ss', ss),\n",
    "    ('smote', smote),\n",
    "    ('dt', dt)\n",
    "])\n",
    "\n",
    "pipe_ss_smote_dt_params = {\n",
    "    'ss__with_mean': [False], # True\n",
    "    'ss__with_std': [True],  # False\n",
    "    'smote__k_neighbors': [7], # 3, 5, 9, 11, 15\n",
    "    'smote__random_state': [42],\n",
    "    'smote__n_jobs': [-1],\n",
    "    'smote__sampling_strategy': ['minority'],\n",
    "    'dt__max_depth': [15], # 5, 10, 20, 25, 30\n",
    "    'dt__max_features': [1.0], # 0.5, 0.75, 0.9\n",
    "    'dt__random_state': [42],\n",
    "}\n",
    "\n",
    "gs_ss_smote_dt = GridSearchCV(\n",
    "    estimator=pipe_ss_smote_dt,\n",
    "    param_grid=pipe_ss_smote_dt_params,\n",
    "    scoring='roc_auc',\n",
    "    cv=5\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd67da11",
   "metadata": {},
   "outputs": [],
   "source": [
    "gs_model(gs_ss_smote_dt, 'SS, Smote, DTree')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6baeb029",
   "metadata": {},
   "source": [
    "**Observations:**\n",
    "\n",
    "We observe a higher accuracy and specificity in our decision tree classifier model as compared to our logistic models. However, the results pale when we measure against our metrics of concern: sensitivity and roc_auc. To be noted that the decision tree classifiers had been optimized to produce the highest roc_auc. Comparing this model to our logistic-lasso regularized model, we find that our decision tree had made significantly higher 'negative' prediction (both true negative and false negative) at 88.6%, as compared to 70.4% in our logistic-lasso regularized model, creating a greater imbalance between 'true' and 'false' predictions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d04b75e",
   "metadata": {},
   "source": [
    "#### Bagging Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61a3829b",
   "metadata": {},
   "outputs": [],
   "source": [
    "bag = BaggingClassifier()\n",
    "\n",
    "pipe_ss_smote_bag = Pipeline([\n",
    "    ('ss', ss),\n",
    "    ('smote', smote),\n",
    "    ('bag', bag)\n",
    "])\n",
    "\n",
    "pipe_ss_smote_bag_params = {\n",
    "    'ss__with_mean': [True],  # False\n",
    "    'ss__with_std': [True],   # False\n",
    "    'smote__k_neighbors': [9], # 3, 5, 7, 11, 15\n",
    "    'smote__random_state': [42],\n",
    "    'smote__n_jobs': [-1],\n",
    "    'smote__sampling_strategy': ['minority'],\n",
    "    'bag__random_state': [42],\n",
    "    'bag__max_features': [0.3], # 0.2, 0.4, 0.5, 0.75, 1.0\n",
    "    'bag__n_jobs': [-1],\n",
    "    'bag__max_samples': [0.6],    # 0.4, 0.5, 0.7, 0.8, 1.0\n",
    "}\n",
    "\n",
    "gs_ss_smote_bag = GridSearchCV(\n",
    "    estimator=pipe_ss_smote_bag,\n",
    "    param_grid=pipe_ss_smote_bag_params,\n",
    "    scoring='roc_auc',\n",
    "    cv=5\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7ddc4b3",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "gs_model(gs_ss_smote_bag, 'SS, Smote, Bag')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8936a3f",
   "metadata": {},
   "source": [
    "**Observations:**\n",
    "\n",
    "\n",
    "Bagging classifier models are similar to decision tree models that classifies our data based on its features and makes predictions on our test set based on the training set's branching decisions. However, bootstrapped models resamples observations in our models with replacement. This means that while the same techniques are used, the observations run into the algorithms will slightly differ due to the selection of resampled observations. In running our model, a bootstrap classifier essentially votes for the result of the outcome based on averaging the aggregate predictions, which allows our model to do better in the metrics we optimized: roc_auc.\n",
    "\n",
    "Comparing this model to our decision tree model, the bagging model scored slightly better in sensitivity and roc_auc. We believe that this improvement can be attributed to the restriction of the bagging model in using a 60% max sample and 30% max features, as compared to the decision tree, which uses all samples and features available. This lowers the variance in the training set and better predicts our testing set.\n",
    "\n",
    "Similar to our decision tree classifier model, we observe a higher accuracy and specificity in our bagging classifier model as compared to our logistic models. Similarly too, the results pale when we measure against our metrics of concern: sensitivity and roc_auc. To be noted our bagging classifiers had also been optimized for roc_auc. Comparing this model to our best model thus far (logistic-lasso regularized model), we find that our decision tree had made significantly higher 'negative' prediction (both true negative and false negative) at 87.0%, as compared to 70.4% in our logistic-lasso regularized model, creating a greater imbalance between 'true' and 'false' predictions.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9aba840c",
   "metadata": {},
   "source": [
    "#### XGBoost Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3af1f98c",
   "metadata": {},
   "outputs": [],
   "source": [
    "xgboost = xgb.XGBClassifier()\n",
    "\n",
    "pipe_ss_smote_xgb = Pipeline([\n",
    "    ('ss', ss),\n",
    "    ('smote', smote),\n",
    "    ('xgb', xgboost)\n",
    "])\n",
    "\n",
    "pipe_ss_smote_xgb_params = {\n",
    "    'ss__with_mean': [True], # False\n",
    "    'ss__with_std': [True], # False\n",
    "    'smote__k_neighbors': [5], # 3, 7, 9, 11, 13\n",
    "    'smote__random_state': [42],\n",
    "    'smote__n_jobs': [-1],\n",
    "    'smote__sampling_strategy': ['minority'],\n",
    "    'xgb__random_state': [42],\n",
    "    'xgb__n_jobs': [-1],\n",
    "    'xgb__learning_rate': [0.1], # 0.04, 0.07, 0.2, 0.3\n",
    "    'xgb__objective': ['binary:logistic'],\n",
    "    'xgb__n_estimators': [60], # 20, 40, 80, 100, 300, 500\n",
    "    'xgb__eval_metric': ['auc']\n",
    "}\n",
    "\n",
    "gs_ss_smote_xgb = GridSearchCV(\n",
    "    estimator=pipe_ss_smote_xgb,\n",
    "    param_grid=pipe_ss_smote_xgb_params,\n",
    "    scoring='roc_auc',\n",
    "    cv=5\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20a5ad7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "gs_model(gs_ss_smote_xgb, 'SS, Smote, XGBoost')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50930f50",
   "metadata": {},
   "source": [
    "**Observations:**\n",
    "\n",
    "A boosted model uses a subset of features to repeatedly train the model and gradually produce better models in each learning iteration. Unlike a decision tree, a boosted model is shallow and combines weak learners into stronger learners by updating the importance of a non-misclassified feature into the next modeling iteration. This allows a model to continually increase its predictive power while still avoiding an overfitting to the training set. \n",
    "\n",
    "Compared to our previous tree-based models, our boosted model performed better on all of our relevant metrics: sensitivity and roc_auc. Similar to before, we have optimized for roc_auc in this model as well. While our boosted model had predicted a higher proportion of our test set to be 'negative' (89.0%, as compared to 88.6% and 87.0% for our decision tree and bagging model respectively), the usage of shallower trees to sequentially train our model had allowed our model to increase its predictive power. This is the best out of all of our tree-based models thus far."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b634255f",
   "metadata": {},
   "source": [
    "**Feature importance:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85c39c8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_feat_impt = pd.DataFrame(gs_ss_smote_xgb.best_estimator_['xgb'].feature_importances_, index=kaggle_X.columns)\n",
    "xgb_feat_impt.rename(columns={0: 'feature_importance'}, inplace=True)\n",
    "xgb_feat_impt.sort_values(by='feature_importance', ascending=False).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80f12ae2",
   "metadata": {},
   "source": [
    "Looking at the top 5 feature importances in our xgboost models, we find that sunset and sunrise time has the highest effect among all features used. This is similar to our previous finding during data cleaning which suggests that mosquito life cycles and activities are affected by  sunrise/sunset times. Our third most important feature is the species, and this makes sense given the rates at which our higher ordinal value species shows a higher rate of testing for WNV as compared to the species with lower ordinal value."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8aed936f",
   "metadata": {},
   "source": [
    "### Analysis of All Feature Reduction Models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b42898e1",
   "metadata": {},
   "source": [
    "#### Metric Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a860f9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "result.set_index('Model')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fec6761b",
   "metadata": {},
   "source": [
    "To end this section, we compare all of our feature reduction models. To recap, feature reduction was done to prevent our models from overfitting to our training set. We then ran two types of classification methods: logistic-based and tree-based classifiers. The main difference between our logistic and tree classifiers are in its nature in using the input features. Whereas a logistic classifier model penalizes features and prevents an overfitting, tree-based classifiers are greedy learners which utilizes as many features as possible. \n",
    "\n",
    "To conclude, our logistic classifier models had generally performed better than our tree-based classifier models in our metric of concern: sensitivity and roc_auc. As such, we believe that thus far, our logistic models would better fit the need of predicting the WNV."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d85d353f",
   "metadata": {},
   "source": [
    "#### Plot ROC-AUC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b10cb321",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_all_auc(models):\n",
    "    fig, ax = plt.subplots(figsize=(10,10))\n",
    "    axes = {}\n",
    "    for i, m in enumerate(models.keys()):\n",
    "        axes[f'ax{i}'] = plot_roc_curve(m, X_test, y_test, ax=ax, name=models[m])\n",
    "        \n",
    "    plt.plot([0, 1], [0, 1], color='k', linestyle='--')\n",
    "    plt.title('ROC-AUC curve')\n",
    "    plt.xlabel('False Positive Rate (FPR)')\n",
    "    plt.ylabel('True Positive Rate (TPR)')\n",
    "    plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0e59d74",
   "metadata": {},
   "outputs": [],
   "source": [
    "models_built = {\n",
    "    gs_ss_smote_logit_ridge: 'Logit Ridge',\n",
    "    gs_ss_smote_logit_lasso: 'Logit Lasso',\n",
    "    gs_ss_smote_dt: 'Decision Tree',\n",
    "    gs_ss_smote_bag: 'Bagging',\n",
    "    gs_ss_smote_xgb: 'xgboost',\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c86f21d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_all_auc(models_built)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68a69e5f",
   "metadata": {},
   "source": [
    "**ROC Comparison**\n",
    "\n",
    "Plotting the graphs above, we find that our xgboost model performed better than our logistic models. Tree-based models are prone to overfitting due to its greedy nature. This means that a tree-based model prefers maximizing the depth of its branches. However, by using xgboost, we limit the greediness of the model such that the models are created using shallower trees (stumps), and trained through learning each iteration's misclassifications. As such, a boosted model allows the model to be trained with less variance (less overfitting).\n",
    "\n",
    "\n",
    "**Final Model Selection**\n",
    "\n",
    "\n",
    "|Model|Sensitivity|ROC_AUC|AUC|Model Selected?|\n",
    "|-----|-----------|-------|---|---------------|\n",
    "|Logistic-Ridge|0.737|0.731|0.80|\n",
    "|<font color=blue>Logistic-Lasso|<font color=blue>0.746|<font color=blue>0.738|<font color=blue>0.80|<font color=blue><center>Yes</center>|\n",
    "|Decision Tree|0.404|0.653|0.71|\n",
    "|Bagging|0.465|0.677|0.81|\n",
    "|<font color=blue>XGBoost|<font color=blue>0.491|<font color=blue>0.702|<font color=blue>0.85|<font color=blue><center>Yes</center>|\n",
    "\n",
    "\n",
    "**Selected models are colorized <font color=blue>BLUE</font> for better readability.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "482592f2",
   "metadata": {},
   "source": [
    "### Run Model for Kaggle\n",
    "\n",
    "This section provides a function to run our feature reduction models and test it against the Kaggle testing set. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c4122f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def kaggle_test(gs_model):\n",
    "    y_pred = gs_model.best_estimator_.predict_proba(kaggle_X)\n",
    "\n",
    "    kaggle_submit = test[['id']]\n",
    "    kaggle_submit['WnvPresent'] = pd.DataFrame(y_pred[:,1])\n",
    "    kaggle_submit.set_index('id', inplace=True)\n",
    "    \n",
    "    return kaggle_submit\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a9bca82",
   "metadata": {},
   "outputs": [],
   "source": [
    "kaggle_submit = kaggle_test(gs_ss_smote_logit_ridge)\n",
    "kaggle_submit.to_csv(r'../data/gs_ss_smote_logit_ridge.csv')\n",
    "kaggle_submit = kaggle_test(gs_ss_smote_logit_lasso)\n",
    "kaggle_submit.to_csv(r'../data/gs_ss_smote_logit_lasso.csv')\n",
    "kaggle_submit = kaggle_test(gs_ss_smote_dt)\n",
    "kaggle_submit.to_csv(r'../data/gs_ss_smote_dt.csv')\n",
    "kaggle_submit = kaggle_test(gs_ss_smote_bag)\n",
    "kaggle_submit.to_csv(r'../data/gs_ss_smote_bag.csv')\n",
    "kaggle_submit = kaggle_test(gs_ss_smote_xgb)\n",
    "kaggle_submit.to_csv(r'../data/gs_ss_smote_xgb.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d88b4990",
   "metadata": {},
   "source": [
    "## Feature extraction \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73290115",
   "metadata": {},
   "source": [
    "### Polynomial Features\n",
    "\n",
    "Any of the features could be related to each other, or have an interactive effect with each other. Any synergistic effect on wnvpresent could increase the significant predictive power to the model. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a37b93d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 'nummosquitos' was removed from polynomial features because it is not a feature in the test set\n",
    "# 'date' was removed as we extracted the 'week', 'year' from it.\n",
    "X = train.drop(columns=['date','wnvpresent','nummosquitos'])\n",
    "y = train['wnvpresent']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca7be065",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generating the polynomial features table.  \n",
    "# instantiate\n",
    "poly = PolynomialFeatures(include_bias=False, degree=2)\n",
    "\n",
    "# fit and transform the variables in the numerical dataframe\n",
    "X_poly = poly.fit_transform(X)\n",
    "X_poly.shape\n",
    "\n",
    "# Checking column names to all polynomial features\n",
    "X_poly = pd.DataFrame(X_poly,columns=poly.get_feature_names(X.columns))\n",
    "\n",
    "# Generating list of poly feature correlations\n",
    "X_poly_corrs = X_poly.corrwith(y)\n",
    "\n",
    "# Shows top 40 features most positively correlated with wnvpresent\n",
    "X_poly_corrs.sort_values(ascending=False).head(40)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b8a9c93",
   "metadata": {},
   "source": [
    "The above showed that the highest correlation seemed to be location (trap_rank and addressaccuracy) related. From EDA, we already know that trap_rank has high correlation, and might not be necessary to add another feature related to trap_rank. In addition, nummosquitoes is not in the test set. So we think adding more features related to temperature such as 'species_nr dewpoint', 'tmin sunrise', 'wetbulb sunrise' would increase the predictive power of our model.\n",
    "\n",
    "It is also important to note features that might have the highest negative impact on wnvpresent. The below list shows that longitude and sunset might have decrease/discourage the presence of wnvpresent. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c009f9a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Shows bottom 20 features most positively correlated with wnvpresent\n",
    "X_poly_corrs.sort_values(ascending=False).tail(20) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "010734e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding interaction features into train set\n",
    "train['species_nr*dewpoint'] = train['species_nr'] * train['dewpoint']\n",
    "train['tmin*sunrise'] = train['tmin'] * train['sunrise']\n",
    "train['wetbulb*sunrise'] = train['wetbulb'] * train['sunrise']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3740ce0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# final train set\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "288dd016",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding interaction features into test set\n",
    "test['species_nr*dewpoint'] = test['species_nr'] * test['dewpoint']\n",
    "test['tmin*sunrise'] = test['tmin'] * test['sunrise']\n",
    "test['wetbulb*sunrise'] = test['wetbulb'] * test['sunrise']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84f1acef",
   "metadata": {},
   "source": [
    "### Exploring PCA-transformed data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e84c353b",
   "metadata": {},
   "source": [
    "For feature extraction, we can use PCA to identify and keep those potential important relationships, before performing the predictions/models. Due to the number of features (and high-dimensional manifold) in our dataset, PCA was utilised to perform an unsupervised dimensionality reduction on the training dataset. In such a way, PCA will provide the best linear approximations before modeling and prediction was performed ([source](https://arxiv.org/ftp/arxiv/papers/1403/1403.1949.pdf)). GridSearchCV is used to set the dimensionality of the PCA. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99eab287",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = train.drop(columns=['date','wnvpresent','nummosquitos'])\n",
    "y = train[['wnvpresent']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c22ef2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77738960",
   "metadata": {},
   "outputs": [],
   "source": [
    "# split again, just to make sure\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(X, y, test_size = 0.33, random_state = 42, stratify =y)\n",
    "\n",
    "# scaling\n",
    "ss_pca = StandardScaler()\n",
    "\n",
    "X_train_sc = ss_pca.fit_transform(X_train)\n",
    "X_valid_sc = ss_pca.transform(X_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "779e3205",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate PCA.\n",
    "# up to n_components were tested\n",
    "pca = PCA(n_components = 10)\n",
    "\n",
    "# Fit PCA on the training data.\n",
    "pca.fit(X_train_sc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4756d5ee",
   "metadata": {},
   "source": [
    "In the below pipeline, PCA will perform unsupervised dimensionality reduction on the training data before upsampling it. This is so that upsampling will only be performed on the reduced dimensional manifold and not on the entire dataset. The models for the prediction will be done last. In the below pipeline, the logistic regression model was utilised. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "201ec555",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe = Pipeline([\n",
    "        ('scale', StandardScaler()),\n",
    "        ('pca', PCA()),\n",
    "        ('sampling', SMOTE()),\n",
    "        ('logreg', LogisticRegression(max_iter=1_000, solver='saga'))\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9920b058",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe_params = {\n",
    "    'pca__n_components': [1, 2, 3, 4, 5, 6, 7, 8, 9, 10],  \n",
    "} "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54e6bc07",
   "metadata": {},
   "outputs": [],
   "source": [
    "grid = GridSearchCV(pipe, pipe_params, scoring='roc_auc', n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d5ff1be",
   "metadata": {},
   "outputs": [],
   "source": [
    "grid.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a155a634",
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://scikit-learn.org/stable/auto_examples/compose/plot_digits_pipe.html#sphx-glr-auto-examples-compose-plot-digits-pipe-py\n",
    "# Plot search for best combination of PCA n_components and logistic regression accuracy\n",
    "# pca.fit(X_train_sc)\n",
    "fig, (ax0, ax1) = plt.subplots(nrows=2, sharex=True, figsize=(6, 6))\n",
    "ax0.plot(np.arange(1, pca.n_components_ + 1),\n",
    "         pca.explained_variance_ratio_.cumsum(), '+', linewidth=10)\n",
    "ax0.set_ylabel('Cumulative PCA explained variance ratio')\n",
    "\n",
    "results = pd.DataFrame(grid.cv_results_)\n",
    "components_col = 'param_pca__n_components'\n",
    "best_clfs = results.groupby(components_col).apply(\n",
    "    lambda g: g.nlargest(1, 'mean_test_score'))\n",
    "\n",
    "best_clfs.plot(x=components_col, y='mean_test_score', yerr='std_test_score',\n",
    "               legend=False, ax=ax1)\n",
    "ax1.set_ylabel('Classification accuracy (val)')\n",
    "ax1.set_xlabel('n_components');\n",
    "plt.suptitle('Dimensional reduction based on PCA n_components');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f323e09a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Cumulative explained variance (for n_components=9): {pca.explained_variance_ratio_.cumsum()[9]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb630c03",
   "metadata": {},
   "outputs": [],
   "source": [
    "grid.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f67592bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "grid.score(X_train, y_train), grid.score(X_valid, y_valid)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68ea1471",
   "metadata": {},
   "source": [
    "GridSearchCV chose n_components=10, however, there was overfitting at n_components=10. Since PCA utilises n_components, the decision is to use n_components=9, to minimise overfitting, and we would retain approximately 83% of the variability in the data.\n",
    "<br>\n",
    "<br> The curse is after the dataset is PCA-transformed, there is no correlation between any features. In addition, the new principal components are not interpretable. So, to dig into the feature importance, one will have to convert the PCA-transformed data back to the original features."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88b78a82",
   "metadata": {},
   "source": [
    "### Loop models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bccf197e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate models\n",
    "models = {'lr': LogisticRegression(max_iter=1000, solver='saga'),\n",
    "        'dt': DecisionTreeClassifier(),\n",
    "        'rf': RandomForestClassifier(),\n",
    "        'et': ExtraTreesClassifier(),\n",
    "        'svc': SVC(probability=True),\n",
    "        } "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd381257",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_models(model, model_params):\n",
    "    pipe = Pipeline([\n",
    "            ('scale', StandardScaler()),\n",
    "            ('pca', PCA(n_components = 9)),\n",
    "            ('sampling', SMOTE(sampling_strategy = 'minority')),\n",
    "            (model, models[model])\n",
    "            ])\n",
    "    \n",
    "    grid = GridSearchCV(pipe, param_grid=model_params, cv=3, scoring='roc_auc', n_jobs=-1)\n",
    "    grid.fit(X_train, y_train)\n",
    "\n",
    "    # metrics\n",
    "    train_score = grid.score(X_train, y_train)\n",
    "    test_score = grid.score(X_valid, y_valid)\n",
    "    preds = grid.predict(X_valid)\n",
    "    tn, fp, fn, tp = confusion_matrix(y_valid, preds).ravel()\n",
    "  \n",
    "    # View confusion matrix\n",
    "    plot_confusion_matrix(grid, X_valid, y_valid, cmap='Blues', values_format='d');\n",
    "    \n",
    "    # Calculate the sensitivity/ recall\n",
    "    sens = tp / (tp + fn)\n",
    "    \n",
    "    # Calculate the specificity\n",
    "    spec = tn / (tn + fp) \n",
    "    \n",
    "    # print results\n",
    "    print(f'Best params: {grid.best_params_}')\n",
    "    print(f'Training score: {round(train_score, 4)}')\n",
    "    print(f'Test score: {round(test_score, 4)}')\n",
    "    print(f'Recall: {round(sens, 4)}')\n",
    "    print(f'Specificity: {round(spec, 4)}')\n",
    "    return grid"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5020f3b1",
   "metadata": {},
   "source": [
    "**Logistic Regression**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7d5746c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# logistic regression\n",
    "grid_params = {\n",
    "    'sampling__k_neighbors': [150, 200, 250],  \n",
    "    'lr__penalty': ['l1', 'l2',  'elasticnet'],   \n",
    "    'lr__C': [0.1, 1, 10]  \n",
    "} \n",
    "\n",
    "best_params = {\n",
    "    'sampling__k_neighbors': [200],  \n",
    "    'lr__penalty': ['l1'],   \n",
    "    'lr__C': [1]  \n",
    "}\n",
    "\n",
    "lr = run_models('lr', best_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "deefcca1",
   "metadata": {},
   "source": [
    "There was little change in tuning the hyperparameters for the logistic regression. There might be an issue with underfitting, since training score < test score. However, it is uncertain (for now) if one of the ways to combat this is to decrease or increase the sampling strategy, since recall was affected, despite having good training and test scores. 'saga' was selected as the 'solver' since it supports several penalties. 'none' was not provided as an option due to tendency of getting training scores = 1.0. So applying regularisation did help to minimise overfitting."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9711ecc7",
   "metadata": {},
   "source": [
    "**Decision Tree Classifier**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28a76103",
   "metadata": {},
   "outputs": [],
   "source": [
    "# decision tree classifier\n",
    "grid_params = {\n",
    "    'sampling__k_neighbors': [15, 20, 25],  \n",
    "    'dt__max_depth': [40, 45, 50],\n",
    "    'dt__min_samples_split': [10, 15, 20],\n",
    "    'dt__min_samples_leaf': [100, 150, 200],\n",
    "} \n",
    "\n",
    "best_params = {\n",
    "    'sampling__k_neighbors': [15],  \n",
    "    'dt__max_depth': [50],\n",
    "    'dt__min_samples_split': [15],\n",
    "    'dt__min_samples_leaf': [100],\n",
    "} \n",
    "\n",
    "dt = run_models('dt', best_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81f06ef1",
   "metadata": {},
   "source": [
    "I do not understand the popularity of decision trees, due to its tendency to overfit, and efforts spent on tuning the parameters to ensure that training score=1.0 does not occur. The hyperparameters are relatively higher (than what I had previously seen), but this was due to training score = 0.999. 'max_depth' is the maximum depth of the tree, where default=None. If None, then nodes are expanded until all the leaves contain less than min_samples_split samples. Since GridSearchCV chooses the estimator based on the highest score, one will have to provide restricted ranges such that training score = 0.999 does not occur. \n",
    "<br> \n",
    "<br> In most parts during hyperparameter selection, there was a balance between providing certain values for GridSearch to tune, such that the higher value of maximum depth does not result in overfitting, and a lower value does not result in underfitting. *(Personal opinion)* higher values should be provided to min_samples_split and min_samples_leaf, however, recall and specificity were penalised/reduced. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97c834c2",
   "metadata": {},
   "source": [
    "**Random forest classifier**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cdb5b4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# random forest classifier\n",
    "grid_params = {\n",
    "    'sampling__k_neighbors': [15, 20, 25], \n",
    "    'rf__n_estimators': [30, 35, 40],\n",
    "    'rf__max_depth': [10, 15, 20],\n",
    "    'rf__min_samples_split': [10, 15, 20],\n",
    "    'rf__min_samples_leaf': [100, 150, 200],\n",
    "} \n",
    "\n",
    "best_params = {\n",
    "    'sampling__k_neighbors': [20], \n",
    "    'rf__n_estimators': [35],\n",
    "    'rf__max_depth': [10],\n",
    "    'rf__min_samples_split': [20],\n",
    "    'rf__min_samples_leaf': [100],\n",
    "} \n",
    "\n",
    "rf = run_models('rf', best_params)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa765833",
   "metadata": {},
   "source": [
    "Ensemble methods are better than simple/one decision tree, due to less probability of overfitting. However, similarly to decision tress (and not totally unexpected), the hyperparameters were relatively higher, but this was due to training score = 0.999. Also (and not totally unexpected), pre-pruning to stop GridSearchCV from growing/cutting down trees was necessary to prevent overfitting. Increasing 'max_depth' would produce better scores; This is not necessary surprising as deeper trees allowed the capture of more information, however, it also increases the likelihood of overfitting. Increasing 'min_samples_leaf' and 'min_samples_split' were essential to ensure that the classifier does not keep splitting the dataset to be more 'pure'. However, there seems to be less issue with recall and specificity in the decision tree and random forests classifiers, compared to logistic regression."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f425344d",
   "metadata": {},
   "source": [
    "**Feature importance**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a1612dd",
   "metadata": {},
   "source": [
    "While PCA is not a classifier and one does not necessarily need to PCA-transform data to get good results, it is important to note that PCA **can** be useful when one has a dataset with high dimensionality. Being able to identify the dimensions first before applying a classifier, may help to discriminate between the classes better. Here, the Random Forest classifier is used to determine the gini importance of the n_components=9, and each feature is plotted below. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7aa081be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://stackoverflow.com/questions/50796024/feature-variable-importance-after-a-pca-analysis\n",
    "# PCA-transform data back to orignal features\n",
    "num_plot = 9\n",
    "\n",
    "pipe = Pipeline([\n",
    "            ('scale', StandardScaler()),\n",
    "            ('pca', PCA(n_components = num_plot)),\n",
    "            ('sampling', SMOTE(sampling_strategy='minority', k_neighbors=200)),\n",
    "            ('rf', RandomForestClassifier(n_estimators=350, max_depth=50, min_samples_split = 200, min_samples_leaf = 100)),\n",
    "            ])\n",
    "\n",
    "pipe.fit(X_train, y_train)\n",
    "\n",
    "model = pipe.steps[1][1]\n",
    "n_pcs = model.components_.shape[0]\n",
    "\n",
    "# get index for more important feature from each n_component\n",
    "feature_names = X_train.columns\n",
    "most_important = [np.abs(model.components_[i]).argmax() for i in range(n_pcs)]\n",
    "most_important_names = [feature_names[most_important[i]] for i in range(n_pcs)]\n",
    "\n",
    "# combine for plotting later\n",
    "zipped_feats = zip(most_important_names, pipe.steps[3][1].feature_importances_)\n",
    "zipped_feats = sorted(zipped_feats, key=lambda x: x[1], reverse=True)\n",
    "features, importances = zip(*zipped_feats)\n",
    "\n",
    "# n_components = 9\n",
    "top_features = features[:num_plot]\n",
    "top_importances = importances[:num_plot]\n",
    "plt.figure(figsize=(10,7))\n",
    "plt.barh(range(len(top_importances)), top_importances, align='center')\n",
    "plt.yticks(range(len(top_importances)), top_features)\n",
    "plt.title('Feature Importances')\n",
    "plt.xlabel('Gini Importance')\n",
    "plt.show() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3238c852",
   "metadata": {},
   "outputs": [],
   "source": [
    "# explained variance attribute of each prinicipal component\n",
    "pipe.steps[1][1].explained_variance_ratio_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfdc129f",
   "metadata": {},
   "source": [
    "The above plots show the nine highest performing predictors. The explained variance ratio provides the information (variance) that is captured by each principal component. So, 'year' explains approximately 28% of the variance in the dataset. 'Sunrise' explains approximately 17% of the variance in the dataset. As demonstrated earlier, n_components=9, could explain approximate 80% of the variability in the dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf9bd995",
   "metadata": {},
   "source": [
    "**year** was a surprise feature. And on hindsight, should have been dropped, if not because we were relying on PCA to transform our entire dataset. How does the year explain 28% of the variability in the dataset? It could be that learning from the past, will bring about wisdom and understanding in the future. During EDA, it was shown that years 2007 and 2013 are years with the highest presence wnv detected. In 2007, a large amount of rain and hot weather produced favourable conditions for eggs ([source](https://www.cmaj.ca/content/177/12/1489.1)). In 2012/2013, was the deadliest year for the wnv in the US due to higher than normal temperatures, and sustained interactions between mosquito and birds (which are reservoir hosts for wnv) ([source](https://www.nbcnews.com/healthmain/2012-was-deadliest-year-west-nile-us-cdc-says-1c9904312))\n",
    "<br>\n",
    "<br> **Sunrise** was not a surprise since mosquitoes are most active around the time of sunrise ([source](https://portal.ct.gov/Mosquito/Press-Room/2020-Press-Releases/DPH-Announces-Three-New-Cases-of-West-Nile-Virus-Infection-in-Fairfield-County.)). \n",
    "<br>\n",
    "<br> **lag_2_preciptotal** and **preciptotal** were not surprising features either, since increased precipitation have a lagged effect on wnvpresent ([source](https://pubmed.ncbi.nlm.nih.gov/30145430/)). However, we were expecting more lagged features from temperatures as well.\n",
    "<br>\n",
    "<br> **wetbulb** was also discussed in EDA. Since wetbulb takes into account both precipitation and temperature, it has demonstrated to have a higher predictive power since it is a feature engineered through combining temperature and precipitation ([source](https://www.theweatherprediction.com/habyhints/259/)).\n",
    "<br>\n",
    "<br> **resultdir** is the resultant wind direction, measured to whole degrees, based on a 360 degree compass (with 0 or 360 degrees from the North). **avgspeed** is the average wind speed. While one would expect higher temperatures and rainfall to dominant the feature importances, it seems *where* and *how fast* the wind is blowing could also be important features. This could be related to FG (fog column)([source](https://www.sciencedaily.com/releases/2012/11/121119104522.htm)), since the spread of wnv requires the mosquitoes to be well conditioned or aided (by wind) for flight.\n",
    "<br>\n",
    "<br> We have discussed the top 2 **species_nr** culex pipiens, culex restuans that are responsible for the spread of the wnv in our EDA.\n",
    "<br>\n",
    "<br> **longitude** is related to location and possibly where the traps were being placed.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b539f7d9",
   "metadata": {},
   "source": [
    "**Extra trees classifier**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71f48f99",
   "metadata": {},
   "outputs": [],
   "source": [
    "# extra trees classifier\n",
    "grid_params = {\n",
    "    'sampling__k_neighbors': [15, 20, 25],\n",
    "    'et__n_estimators': [30, 35],\n",
    "    'et__max_depth': [4, 5, 6],\n",
    "    'et__min_samples_split': [10, 15],\n",
    "    'et__min_samples_leaf': [10, 15],\n",
    "} \n",
    "\n",
    "best_params = {\n",
    "    'sampling__k_neighbors': [20],\n",
    "    'et__n_estimators': [30],  \n",
    "    'et__max_depth': [4],  \n",
    "    'et__min_samples_split': [15],\n",
    "    'et__min_samples_leaf': [10],\n",
    "}\n",
    "\n",
    "et = run_models('et', best_params)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebd14440",
   "metadata": {},
   "source": [
    "Extra trees implements a meta estimator that fits a number of randomized decision trees on various sub-samples of the dataset. It should improve the accuracy while control for over-fitting. So far, this has been true; The number of trees are fewer, and do not need to be deep (max_depth) to produce good scores. Increasing the n_estimators also increased the accuracy, but up to a certain point (in this case, 30 trees). min_samples_split and min_samples_leaf do not have to be large to avoid overfitting. Feature importance was not performed because n_components=9 was used for all the models using PCA-transformed data, and they are the same 9 features. *(Preliminary analysis found that sunrise and year would fight to be top dog in the different models, but that was just a small difference)*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9548a11",
   "metadata": {},
   "source": [
    "**Support Vector Classification**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3cfe9ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Support Vector Classification\n",
    "grid_params = {\n",
    "    'sampling__k_neighbors': [250, 300],     \n",
    "    'svc__kernel': ['linear', 'sigmoid'],   \n",
    "    'svc__gamma' : ['scale', 'auto'], \n",
    "    'svc__C': [1 ,5 ,10] \n",
    "} \n",
    "\n",
    "best_params = {\n",
    "    'sampling__k_neighbors': [250],     \n",
    "    'svc__kernel': ['linear'],    \n",
    "    'svc__gamma' : ['scale'],\n",
    "    'svc__C': [1] \n",
    "} \n",
    "\n",
    "svc = run_models('svc',  best_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "013e3f7b",
   "metadata": {},
   "source": [
    "In the above, hyperparameters tuned were the kernel, gamma and regularization parameter. 'rbf' and 'poly' were not provided as options, as there were instances where training score=0.99 (dependent on other parameters). Choosing an optimal gamma was important too, since the parameter controls overfitting; The higher the gamma, the higher the hyperplane to match the training data. A regularization parameter C represents the tradeoff between a smoother hyperplane and misclassifications. In summary, SVM is known to work well with non-linear data, is simple to implement, and provided high accuracy. However, it requires a lot of training time compared to other algorithms. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd542232",
   "metadata": {},
   "source": [
    "### Analysis of All Feature Extraction Models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b409cd92",
   "metadata": {},
   "source": [
    "#### Metric Comparison"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4741375",
   "metadata": {},
   "source": [
    "|                           | ROC_AUC | Sensitivity | Specificity |\n",
    "|---------------------------|---------|-------------|-------------|\n",
    "| Logistic regression       | 0.93    | 0.83        | 0.86        |\n",
    "| Decision Tree classifier  | 0.94    | 0.81        | 0.94        |\n",
    "| Random Forest classifier  | 0.97    | 0.83        | 0.95        |\n",
    "| Extra Trees classifier    | 0.93    | 0.87        | 0.85        |\n",
    "| Support Vector classifier | 0.93    | 0.82        | 0.86        |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81acf287",
   "metadata": {},
   "source": [
    "#### Plot ROC-AUC "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d76159b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_all_auc(models):\n",
    "    fig, ax = plt.subplots(figsize=(10,10))\n",
    "    axes = {}\n",
    "    for i, m in enumerate(models.keys()):\n",
    "        axes[f'ax{i}'] = plot_roc_curve(m, X_valid, y_valid, ax=ax, name=models[m])\n",
    "        \n",
    "    plt.plot([0, 1], [0, 1], color='k', linestyle='--')\n",
    "    plt.title('ROC-AUC curve')\n",
    "    plt.xlabel('False Positive Rate (FPR)')\n",
    "    plt.ylabel('True Positive Rate (TPR)')\n",
    "    plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fba54cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "models_built = {\n",
    "    lr : 'LogisticRegression', \n",
    "    dt : 'DecisionTreeClassifier',\n",
    "    rf : 'RandomForestClassifier',\n",
    "    et : 'ExtraTreesClassifier',\n",
    "    svc : 'SVC',\n",
    "} "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bd2a221",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_all_auc(models_built)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a11c076c",
   "metadata": {},
   "source": [
    "From the above ROC-AUC curve, the Random Forest classifier has the highest AUC score, ie., it is better at predicting classes or distinguishing between the classes. So the Random Forest model also presents the best performing trade-off between the true positives and true negatives. In addition, the model has a recall rate at 0.83, and specificity at 0.95. Therefore, using PCA-transformed data, **the Random Forest model was selected as the chosen model.**\n",
    "<br>\n",
    "<br> At FPR=1, where sensitivity is the highest, all classifiers seemed to performed well till FPR=0.8. Below this point, the decision tree (dt) classifier starts to exhibit lower sensitivity, with the lowest sensitivity (=0.81) reported among all the models. Given the tendency for dt to overfit, the parameters were tuned such that a training score = 0.999 did not occur, however, sensitivity was also penalised. At FPR=0, where specificity is the highest, the sudden decrease in logistic regression showed that the model, together with SVC have the lowest specificity.\n",
    "<br>\n",
    "<br> Due to excessive restrictions on overfitting, some models exhibited underfitting. Perhaps depending on PCA to reduce the dimension and transform the data restricted/prevented the model from learning and understanding the complexities of the dataset. In this case, between underfitting and overfitting, the decision here was to restrict overfitting. Due to the multicollinearity of the data, for example, in the weather dataset, where most (if not all) of the dataset are close cousins of each other, the data used should be simplified and this will also enable use of a less complex model. If one can utilise a better dataset with more information on spraying, then this will justify the use of a more complex model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebb1d102",
   "metadata": {},
   "source": [
    "## Run Model for Kaggle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "997be836",
   "metadata": {},
   "outputs": [],
   "source": [
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b71c6dd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop columns\n",
    "X_test = test.drop(columns=['id','date'])\n",
    "\n",
    "# check that shape is same to train dataset\n",
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffb2d4e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = train.drop(columns=['date','wnvpresent','nummosquitos'])\n",
    "y = train[['wnvpresent']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e225216",
   "metadata": {},
   "outputs": [],
   "source": [
    "# arrange columns to match\n",
    "X = X[X_test.columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a89905e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_test(model, model_params):\n",
    "    pipe = Pipeline([\n",
    "            ('scale', StandardScaler()),\n",
    "            ('pca', PCA(n_components = 9)),\n",
    "            ('sampling', SMOTE()),\n",
    "            (model, models[model])\n",
    "            ])\n",
    "    \n",
    "    grid = GridSearchCV(pipe, param_grid=model_params, scoring='roc_auc', n_jobs=-1)\n",
    "    grid.fit(X, y)\n",
    "\n",
    "    train_score = grid.score(X, y)\n",
    "#     preds = grid.predict(X_test)\n",
    "    pred_prob = grid.predict_proba(X_test)\n",
    "    \n",
    "    print(f'Training score: {round(train_score, 4)}')\n",
    "    return pred_prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9da38f0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random Forest Classification\n",
    "best_params = {\n",
    "    'sampling__k_neighbors': [20], \n",
    "    'rf__n_estimators': [35],\n",
    "    'rf__max_depth': [10],\n",
    "    'rf__min_samples_split': [20],\n",
    "    'rf__min_samples_leaf': [100],\n",
    "} \n",
    "\n",
    "y_pred = run_test('rf', best_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c63cab8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# kaggle score = 0.61\n",
    "kaggle_rf = test[['id']]\n",
    "kaggle_rf['wnvpresent'] = pd.DataFrame(y_pred[:,1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4acb6cb7",
   "metadata": {},
   "source": [
    "**Save predicted results as csv file for kaggle submission.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9430f8e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "kaggle_rf.to_csv('../data/kaggle_rf.csv',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bd7741b",
   "metadata": {},
   "source": [
    "# Predicted locations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d92e66c6",
   "metadata": {},
   "source": [
    "The predictions were based on our model of choice which was selected from models built on feature reduction. This is because feature reduction allowed us to filter irrelevant or redundant features based on domain knowledge; It is a relatively safer technique to ensure that the features that have been 'proven' to possess high predictive power to be included in the model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76c14b7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting up predictions in a dataframe for merging\n",
    "predictions = pd.DataFrame(gs_ss_smote_xgb.best_estimator_.predict(kaggle_X)).reset_index()\n",
    "predictions['index'] = predictions['index'] + 1\n",
    "predictions = predictions.rename(columns={0: 'predictions', 'index': 'id'})\n",
    "\n",
    "# Setting up test for merging\n",
    "plot_map = test[['id', 'latitude', 'longitude', 'week']]\n",
    "\n",
    "# Merging plot_map and predictions\n",
    "plot_map = pd.merge(\n",
    "    left=plot_map,\n",
    "    right=predictions,\n",
    "    left_on='id',\n",
    "    right_on='id'\n",
    ")\n",
    "\n",
    "# Selecting only the areas which are predicted to have WNV\n",
    "plot_map_positive = plot_map.loc[plot_map['predictions'] != 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a723e26e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://www.kaggle.com/c/predict-west-nile-virus/\n",
    "# This shows how to read the text representing a map of Chicago in numpy, and put it on a plot in matplotlib.\n",
    "# This example also rescales the image data to the GPS co-ordinates of the bounding box and overlays some random points.\n",
    "\n",
    "origin = [41.6, -88.0]              # lat/long of origin (lower left corner)\n",
    "upperRight = [42.1, -87.5]          # lat/long of upper right corner\n",
    "\n",
    "mapdata = np.loadtxt('../data/mapdata_copyright_openstreetmap_contributors.txt')\n",
    "\n",
    "# # Uncomment below and adjust week_num to find spray location of said week.\n",
    "# week_num = -insert week number-\n",
    "# plot_week = plot_map_positive.loc[plot_map_positive['week'] == week_num]\n",
    "# lats = plot_week['latitude']\n",
    "# longs = plot_week['longitude']\n",
    "# hue = plot_week['week']\n",
    "\n",
    "lats = plot_map_positive['latitude']\n",
    "longs = plot_map_positive['longitude']\n",
    "hue = plot_map_positive['week']\n",
    "\n",
    "plt.figure(figsize=(10,10))\n",
    "\n",
    "# generate plot\n",
    "plt.imshow(mapdata, cmap=plt.get_cmap('gray'), extent=[origin[1], upperRight[1], origin[0], upperRight[0]])\n",
    "sns.scatterplot(x=longs, y=lats, \n",
    "                palette='Paired', \n",
    "                hue=hue,\n",
    "                legend='full', \n",
    "                s=100,\n",
    "               )\n",
    "\n",
    "plt.title('Spray Locations by Week Number', size=20)\n",
    "\n",
    "plt.savefig('map_predict.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5057f94",
   "metadata": {},
   "source": [
    "The above map shows the overall spray areas for weeks 29 to 39. The graph colours segregate the week numbers to which the sprays should be done on each location. Note that some areas are overlapping, and thus the map should be adjusted to find each weekly spray location. We have commented out a few lines of code for the user to input their week of interest and find the spray locations."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d700a29",
   "metadata": {},
   "source": [
    "# Conclusions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d7ea06b",
   "metadata": {},
   "source": [
    "Our client requested for us to provide suggestions of when and where to spray for mosquitoes which have the West Nile Virus in order to decrease their city's rate of infection and death rate. We recommend that pesticides be deployed in inner suburbs (refer to map above), and that older housing (built in the 40s-60s) be given priority due to their older sewer systems which are favourable breeding grounds for mosquito breeding. Furthermore, we recommend that spraying should be done 14 days earlier given that there is a max 14-day WNV incubation period. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9533cb4e",
   "metadata": {},
   "source": [
    "The model of choice was selected from models built on feature reduction. This is because feature reduction allowed us to filter irrelevant or redundant features based on domain knowledge; It is a relatively safe technique to ensure that the features that have been 'proven' to possess high predictive power to be included in the model. \n",
    "\n",
    "We iterate some of our findings to conclude our findings.\n",
    "\n",
    "1. Due to an imbalanced target class, Smoting was necessary to reduce such imbalance and provide the model with more balanced data.\n",
    "2. Our logistic based models generally performed better than our fancier tree-based classifiers due to a tree-based model\n",
    "3. However, using a boosted model is preferrable to a logistic model due to its ability to train with less overfitting as compared to other tree-based models and producing a better ROC.\n",
    "\n",
    "\n",
    "**Models selected:** Smoted Logistic Lasso Model and Smoted XGBoost Model\n",
    "\n",
    "|Model|Sensitivity|ROC_AUC|AUC|Kaggle Score|\n",
    "|-----|-----------|-------|---|------------|\n",
    "|Logistic-Lasso|0.746|0.738|0.80|0.72469|\n",
    "|XGBoost|0.491|0.702|0.85|0.75119|\n",
    "\n",
    "Our smoted logistic model penalized using lasso regularization was selected due to several reasons:\n",
    "\n",
    "1. Higher ROC_AUC and Sensitivity Scores\n",
    "2. Faster computational time\n",
    "\n",
    "We also select our smoted XGBoost model due to the following reasons:\n",
    "\n",
    "1. Less overfitting as compared to our tree-based models\n",
    "2. Highest AUC score.\n",
    "\n",
    "\n",
    "We find that models based on tree-based classifiers such as decision trees, bagging and boosting performed much worse than our logistic-based classification models. The worse performance can be attributed to the nature of tree-based classifiers. Tree-based classifiers are greedy algorithms that tend to overfit. On the other hand, logistic-based regressions that have been penalized with L1 and/or L2 regularization do not suffer from the same problem of overfitting. While optimization of tree-based classifiers can decrease variance, they do not perform as well as other models that we are using. As such, we believe that the logistic models are generally more reliable than the tree-based models.\n",
    "\n",
    "However, our boosted model performed better than our logistic models. The reason is that a boosted model trains in such a way that prevents overfitting due to its usage of shallower trees. As such, it is able to perform better than other tree models as it relies continually improves itself through the changing weights of the models on each iteration. A caveat to using boosted models: a boosted model requires more computational time than a logistic based model. Specifically, a boosted model will take the most time as one model is trained based on the previous model. As such, a boosted model cannot compute in a parallel manner and must instead be computed sequentially."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d2ab7db",
   "metadata": {},
   "source": [
    "In determining the cost-effectiveness of deploying pesticides, we predicted that the economic impact of the 2013 WNV would cost approximately US\\\\$2,000,000 for 100 people requiring medical treatment. The costs for aerial spray is estimated to be US\\\\$815,355. Therefore, preventing WNV cases would not only save lives, but this will further avert economic costs (offsetting the cost of aerial spray). "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "243fffab",
   "metadata": {},
   "source": [
    "## Recommendations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5e4cc7c",
   "metadata": {},
   "source": [
    "We provide several recommendations on improving our model's predictive power, and other things that our client may take into consideration in their fight against the West Nile Virus.\n",
    "\n",
    "**Short Term Recommendations:**\n",
    "\n",
    "1. We recommend the collection and inclusion of additional relevant data such as:\n",
    "    1. Population density\n",
    "    2. Housing density\n",
    "    3. Housing year built\n",
    "    4. Sewage flow\n",
    "    5. Increased number of traps \n",
    "    6. Humidity\n",
    "    7. Sunlight duration\n",
    "    8. Migratory patterns of birds (which are amplifying reservoirs/ hosts for WNV)\n",
    "\n",
    "2. We recommend a cross-analysis of WNV cases in other states with similar weather patterns which also experience seasonal cases of WNV.\n",
    "\n",
    "3. We recommend dropping the 'year' feature. Despite year being one of the feature importance in our model (after PCA-transform), the focus should be on weather conditions which will impede/encourage mosquitoes breeding and proliferation, rather than seasonal changes, even if present.\n",
    "\n",
    "4. We recommend dummifying trap numbers instead of ranking them. While we had ranked the traps by groups based on the current amount of WNV mosquitos caught as we believe that it would provide much predictive power to our model, doing so may have been one of the causes of overfitting in our models. Dummifying trap ranks may provide a similar amount of predictive power while reducing variance.\n",
    "\n",
    "\n",
    "**Long Term Recommendations:**\n",
    "\n",
    "In the long term, our client should explore other alternative ways to fight against the West Nile Virus such as developing anti-WNV mosquitos. Modified mosquitos such as the modified [Aedes aegypti](https://www.webmd.com/a-to-z-guides/genetically-modified-mosquitoes) developed to combat against dengue, Zika, yellow fever and chikungunya are meant to prevent such diseases from occurring by introducing genetically engineered mosquitos to the population and disabling female offsprings from reproducing. This provides a targeted method of eliminating WNV-infected mosquitos which may grow resistant to the pesticides sprayed, and reduces the recurring annual cost of spraying pesticides.\n",
    "\n",
    "**Creative (Humorous) Recommendation:**\n",
    "\n",
    "In the mid-1300s, Europe was struck by the Bubonic Plague. More commonly known as the Black Death, the plague caused the death of millions of Europeans. In response to this, households were decreed to have a [cat to catch and kill](https://www.museumcenter.org/the-curious-curator/2018/7/16/black-cats-and-biological-warfare-the-history-of-the-plague) its main perpetuator: mice. Replicating the wisdom of the past, the governor could decree that every household must own a few frogs to eat the mosquitoes.\n",
    "\n",
    "In 2020, China had faced a crisis plague which threatened regional food security - a Locust Plague. In response, China's government [enlisted 100,000 ducks](https://time.com/5791466/ducks-locust-plague/) to eat the locusts. On average, a single duck can eat 200 locusts in a day. This biological weapon used by China was more effective than utilizing pesticides that may threaten their crops. Similarly, the governor could introduce a large amount of frogs into the city to combat the WNV mosquitos."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "383.993px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
